<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Future of Artificial Intelligence - Video Article</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,400&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <nav class="top-nav">
        <div class="nav-content">
            <div class="nav-logo">VideoArticle</div>
            <div class="nav-actions">
                <button class="nav-btn">Browse</button>
                <button class="nav-btn primary">Subscribe</button>
            </div>
        </div>
    </nav>

    <div class="container">
        <!-- Breadcrumb -->
        <div class="breadcrumb">
            <a href="#">Home</a>
            <span class="breadcrumb-separator">‚Ä∫</span>
            <a href="#">Technology</a>
            <span class="breadcrumb-separator">‚Ä∫</span>
            <span>AI Ethics</span>
        </div>

        <!-- Hero Section -->
        <header class="hero">
            <h1 class="video-title">The Future of Artificial Intelligence: A Deep Dive into Machine Learning Ethics</h1>
            
            <div class="meta-bar">
                <div class="author-info">
                    <img src="https://i.pravatar.cc/80?img=12" alt="Channel avatar" class="author-avatar">
                    <div class="author-details">
                        <a href="#" class="author-name">Tech Insights Channel</a>
                        <div class="author-meta">
                            <time datetime="2024-01-15">Jan 15, 2024</time>
                            <span class="separator">‚Ä¢</span>
                            <span class="read-time">12 min read</span>
                            <span class="separator">‚Ä¢</span>
                            <span class="video-length">24:15 video</span>
                        </div>
                    </div>
                </div>
                <div class="engagement-stats">
                    <span class="stat">üëÅÔ∏è 1.2M</span>
                    <span class="stat">üëç 45K</span>
                    <span class="stat">üí¨ 2.3K</span>
                </div>
            </div>

            <div class="video-embed">
                <div class="video-wrapper">
                    <img src="https://picsum.photos/1200/675?random=1" alt="Video thumbnail" class="video-thumbnail-img">
                    <div class="play-button">
                        <svg width="100" height="100" viewBox="0 0 100 100">
                            <circle cx="50" cy="50" r="45" fill="rgba(0,0,0,0.7)" stroke="white" stroke-width="2"/>
                            <polygon points="40,30 40,70 70,50" fill="white"/>
                        </svg>
                    </div>
                    <div class="video-duration">24:15</div>
                </div>
            </div>
        </header>

        <!-- Main Article Content -->
        <article class="main-content">
            <div class="article-intro">
                <p class="lead-paragraph">In an era where artificial intelligence shapes everything from our social media feeds to critical healthcare decisions, the ethical implications of machine learning have never been more crucial. Join Dr. Sarah Chen, Stanford's leading AI ethics researcher, and Professor Michael Rodriguez from UC Berkeley as they unpack the complex moral landscape of algorithmic decision-making.</p>
            </div>

            <div class="key-highlights">
                <div class="highlights-header">
                    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M12 2L2 7l10 5 10-5-10-5z"/>
                        <path d="M2 17l10 5 10-5"/>
                        <path d="M2 12l10 5 10-5"/>
                    </svg>
                    <h2>Key Insights</h2>
                </div>
                <div class="highlights-grid">
                    <div class="highlight-card">
                        <div class="highlight-icon">üéØ</div>
                        <h3>Algorithmic Bias</h3>
                        <p>AI systems can perpetuate and amplify existing social inequalities through biased training data</p>
                    </div>
                    <div class="highlight-card">
                        <div class="highlight-icon">üîç</div>
                        <h3>Transparency Crisis</h3>
                        <p>The "black box" problem makes it difficult to understand and audit AI decision-making processes</p>
                    </div>
                    <div class="highlight-card">
                        <div class="highlight-icon">‚öñÔ∏è</div>
                        <h3>Regulatory Evolution</h3>
                        <p>New frameworks like the EU AI Act are attempting to balance innovation with citizen protection</p>
                    </div>
                </div>
            </div>

            <div class="article-body">
                <h2>The Hidden Patterns of Algorithmic Bias</h2>
                <p>The conversation opens with a deceptively simple question: Can machines be prejudiced? Dr. Chen's answer challenges our understanding of both technology and fairness. Machine learning systems, she explains, don't create bias from nothing‚Äîthey learn it from us, encoding centuries of human prejudice into lines of code.</p>

                <figure class="pull-quote left">
                    <blockquote>
                        "We're not creating neutral systems‚Äîwe're creating mirrors of our society, with all its flaws and biases encoded into the algorithms."
                    </blockquote>
                    <figcaption>
                        <div class="quote-author">Dr. Sarah Chen</div>
                        <a href="#" class="quote-timestamp" data-timestamp="05:23">
                            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polyline points="12 6 12 12 16 14"/>
                            </svg>
                            05:23
                        </a>
                    </figcaption>
                </figure>

                <p>Consider the case that Professor Rodriguez presents: a Fortune 500 company's hiring algorithm, trained on a decade of employment data. On the surface, the system appeared to be working efficiently, processing thousands of applications and identifying top candidates. But a closer examination revealed a troubling pattern‚Äîthe algorithm consistently ranked female candidates lower than their male counterparts with identical qualifications.</p>

                <div class="media-figure">
                    <img src="https://picsum.photos/1200/675?random=2" alt="Algorithmic bias visualization" class="figure-image">
                    <div class="media-caption">
                        <div class="caption-text">Visualization showing how biased training data leads to discriminatory outcomes in hiring algorithms</div>
                        <a href="#" class="caption-timestamp" data-timestamp="08:15">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polyline points="12 6 12 12 16 14"/>
                            </svg>
                            08:15
                        </a>
                    </div>
                </div>

                <p>The root cause? Historical data reflected the company's past hiring patterns, which inadvertently favored male candidates. The algorithm didn't know it was being discriminatory‚Äîit simply learned what "success" looked like based on who had been hired before. This case study illuminates a fundamental challenge: how do we build fair systems when our training data reflects an unfair world?</p>

                <div class="info-box">
                    <div class="info-box-header">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"/>
                            <line x1="12" y1="16" x2="12" y2="12"/>
                            <line x1="12" y1="8" x2="12.01" y2="8"/>
                        </svg>
                        <span>Real-World Impact</span>
                    </div>
                    <p>Studies have shown that facial recognition systems have error rates up to 35% higher for people with darker skin tones, and voice recognition systems struggle with non-native accents. These aren't just technical problems‚Äîthey're social justice issues with real consequences for millions of people.</p>
                </div>

                <h2>The Transparency Paradox</h2>
                <p>As algorithms grow more sophisticated, they become increasingly opaque. Professor Rodriguez introduces what he calls the "transparency paradox"‚Äîthe more powerful an AI system becomes, the harder it is to explain how it works.</p>

                <div class="two-column-layout">
                    <div class="column">
                        <p>Deep learning models can have billions of parameters, making their decision-making processes virtually impossible for humans to fully comprehend. This creates a profound challenge when these systems are deployed in high-stakes environments like healthcare, criminal justice, or financial lending.</p>
                    </div>
                    <div class="column">
                        <div class="stat-callout">
                            <div class="stat-number">73%</div>
                            <div class="stat-label">of Americans say they wouldn't trust an AI system they can't understand</div>
                            <div class="stat-source">‚Äî Pew Research, 2023</div>
                        </div>
                    </div>
                </div>

                <figure class="pull-quote right">
                    <blockquote>
                        "If we can't explain why an AI system made a particular decision, how can we trust it with critical applications like healthcare or criminal justice?"
                    </blockquote>
                    <figcaption>
                        <div class="quote-author">Prof. Michael Rodriguez</div>
                        <a href="#" class="quote-timestamp" data-timestamp="12:47">
                            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polyline points="12 6 12 12 16 14"/>
                            </svg>
                            12:47
                        </a>
                    </figcaption>
                </figure>

                <p>The discussion turns to explainable AI (XAI)‚Äîa field dedicated to making machine learning models interpretable. Dr. Chen demonstrates several techniques, from simple feature importance rankings to complex SHAP (SHapley Additive exPlanations) values, that help humans understand what drives an algorithm's predictions.</p>

                <div class="media-figure">
                    <img src="https://picsum.photos/1200/675?random=3" alt="Explainable AI visualization" class="figure-image">
                    <div class="media-caption">
                        <div class="caption-text">Example of SHAP values showing which features most influenced an AI model's decision</div>
                        <a href="#" class="caption-timestamp" data-timestamp="15:30">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polyline points="12 6 12 12 16 14"/>
                            </svg>
                            15:30
                        </a>
                    </div>
                </div>

                <h2>Regulating the Future</h2>
                <p>The conversation shifts to the regulatory landscape, where both experts agree that we're at a critical juncture. The European Union's AI Act represents one of the most comprehensive attempts to regulate artificial intelligence, categorizing AI systems by risk level and imposing stricter requirements on high-risk applications.</p>

                <p>But regulation is a double-edged sword. Too restrictive, and it could stifle innovation and push development to less regulated jurisdictions. Too lenient, and it fails to protect citizens from algorithmic harm. Finding the right balance requires technical expertise, ethical reasoning, and political wisdom‚Äîa rare combination.</p>

                <div class="media-figure">
                    <img src="https://picsum.photos/1200/675?random=4" alt="EU AI Act framework" class="figure-image">
                    <div class="media-caption">
                        <div class="caption-text">Overview of the EU AI Act's risk-based classification system for AI applications</div>
                        <a href="#" class="caption-timestamp" data-timestamp="18:32">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polyline points="12 6 12 12 16 14"/>
                            </svg>
                            18:32
                        </a>
                    </div>
                </div>

                <h2>Building a Better Future</h2>
                <p>The discussion concludes with a forward-looking perspective. Both Dr. Chen and Professor Rodriguez emphasize that ethical AI isn't just about avoiding harm‚Äîit's about actively creating systems that promote fairness, transparency, and human flourishing.</p>

                <p>They outline several key principles for responsible AI development: diverse teams building the systems, inclusive data collection processes, regular audits for bias and fairness, transparency about limitations, and mechanisms for human oversight and appeal. These aren't just technical requirements‚Äîthey're moral imperatives for anyone working with AI.</p>
            </div>

            <!-- Timeline Section -->
            <section class="timeline-section">
                <div class="section-header">
                    <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="10"/>
                        <polyline points="12 6 12 12 16 14"/>
                    </svg>
                    <h2>Video Timeline</h2>
                </div>
                <p class="section-description">Jump to key moments in the discussion</p>
                
                <div class="timeline-scroll">
                    <div class="timeline-item" data-timestamp="00:00">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=5" alt="Introduction">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">00:00</span>
                            <h4>Introduction</h4>
                            <p>Setting the stage for the AI ethics discussion</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="05:23">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=6" alt="Algorithmic bias">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">05:23</span>
                            <h4>Understanding Algorithmic Bias</h4>
                            <p>Dr. Chen explains how AI systems inherit human prejudices</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="08:15">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=7" alt="Case study">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">08:15</span>
                            <h4>Case Study: Hiring Algorithm</h4>
                            <p>Real-world example of discrimination in AI systems</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="12:47">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=8" alt="Transparency">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">12:47</span>
                            <h4>The Black Box Problem</h4>
                            <p>Why we struggle to understand AI decisions</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="15:30">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=9" alt="Explainable AI">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">15:30</span>
                            <h4>Explainable AI Techniques</h4>
                            <p>Tools and methods for understanding algorithms</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="18:32">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=10" alt="Regulation">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">18:32</span>
                            <h4>The EU AI Act</h4>
                            <p>Exploring new regulatory frameworks for AI</p>
                        </div>
                    </div>

                    <div class="timeline-item" data-timestamp="21:10">
                        <div class="timeline-thumb">
                            <img src="https://picsum.photos/300/169?random=11" alt="Future">
                            <div class="timeline-play">‚ñ∂</div>
                        </div>
                        <div class="timeline-info">
                            <span class="timeline-time">21:10</span>
                            <h4>Building Ethical AI</h4>
                            <p>Principles for responsible AI development</p>
                        </div>
                    </div>
                </div>
            </section>
        </article>

        <!-- Secondary Content -->
        <aside class="secondary-content">
            <div class="tabs-container">
                <div class="tabs">
                    <button class="tab-button active" data-tab="transcript">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                            <polyline points="14 2 14 8 20 8"/>
                        </svg>
                        Transcript
                    </button>
                    <button class="tab-button" data-tab="people">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M17 21v-2a4 4 0 0 0-4-4H5a4 4 0 0 0-4 4v2"/>
                            <circle cx="9" cy="7" r="4"/>
                            <path d="M23 21v-2a4 4 0 0 0-3-3.87"/>
                            <path d="M16 3.13a4 4 0 0 1 0 7.75"/>
                        </svg>
                        People & Terms
                    </button>
                    <button class="tab-button" data-tab="translations">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"/>
                            <line x1="2" y1="12" x2="22" y2="12"/>
                            <path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/>
                        </svg>
                        Translations
                    </button>
                    <button class="tab-button" data-tab="metadata">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="3"/>
                            <path d="M12 1v6m0 6v6m5.2-14.2l-4.3 4.3m0 5.9l4.3 4.3m5.9-10.5h-6m-6 0H1m14.2 5.2l-4.3-4.3m0-5.9l-4.3-4.3"/>
                        </svg>
                        Details
                    </button>
                </div>

                <!-- Transcript Tab -->
                <div class="tab-content active" id="transcript">
                    <div class="tab-header">
                        <h3>Full Transcript</h3>
                        <div class="tab-controls">
                            <select class="control-select">
                                <option>English (Original)</option>
                                <option>Spanish</option>
                                <option>French</option>
                                <option>German</option>
                                <option>Japanese</option>
                            </select>
                            <input type="search" placeholder="Search in transcript..." class="control-search">
                            <button class="control-btn">
                                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                                    <polyline points="7 10 12 15 17 10"/>
                                    <line x1="12" y1="15" x2="12" y2="3"/>
                                </svg>
                                Download
                            </button>
                        </div>
                    </div>
                    <div class="transcript-content">
                        <div class="transcript-entry" data-time="00:00">
                            <span class="entry-time">00:00</span>
                            <p class="entry-text">Welcome to Tech Insights Channel. Today we're diving deep into one of the most pressing issues of our time: the ethical implications of machine learning and artificial intelligence.</p>
                        </div>
                        <div class="transcript-entry" data-time="00:15">
                            <span class="entry-time">00:15</span>
                            <p class="entry-text">I'm thrilled to be joined by two incredible experts. Dr. Sarah Chen is a leading researcher in AI ethics at Stanford University, and Professor Michael Rodriguez teaches algorithmic fairness at UC Berkeley.</p>
                        </div>
                        <div class="transcript-entry" data-time="00:32">
                            <span class="entry-time">00:32</span>
                            <p class="entry-text">Thank you so much for having us. This conversation is more important than ever. AI is no longer a future technology‚Äîit's here, it's everywhere, and it's making decisions that affect millions of people every single day.</p>
                        </div>
                        <div class="transcript-entry" data-time="05:23">
                            <span class="entry-time">05:23</span>
                            <p class="entry-text">We're not creating neutral systems‚Äîwe're creating mirrors of our society, with all its flaws and biases encoded into the algorithms. Every dataset tells a story, and often that story reflects historical inequalities.</p>
                        </div>
                        <div class="transcript-entry" data-time="08:15">
                            <span class="entry-time">08:15</span>
                            <p class="entry-text">Let me show you a concrete example. This hiring algorithm was trained on ten years of hiring data from a major tech company. On the surface, it seemed to be working perfectly‚Äîprocessing applications faster than any human could.</p>
                        </div>
                        <div class="transcript-entry" data-time="12:47">
                            <span class="entry-time">12:47</span>
                            <p class="entry-text">If we can't explain why an AI system made a particular decision, how can we trust it with critical applications like healthcare or criminal justice? This is what I call the transparency paradox.</p>
                        </div>
                        <div class="transcript-entry" data-time="15:30">
                            <span class="entry-time">15:30</span>
                            <p class="entry-text">Fortunately, there are promising developments in explainable AI. Techniques like SHAP values and LIME allow us to peek inside these black boxes and understand which features are driving decisions.</p>
                        </div>
                        <div class="transcript-entry" data-time="18:32">
                            <span class="entry-time">18:32</span>
                            <p class="entry-text">The EU AI Act represents a significant milestone in AI regulation. It takes a risk-based approach, imposing stricter requirements on high-risk applications like facial recognition or credit scoring.</p>
                        </div>
                        <div class="transcript-entry" data-time="21:10">
                            <span class="entry-time">21:10</span>
                            <p class="entry-text">Building ethical AI requires more than just technical solutions. It requires diverse teams, inclusive processes, regular audits, and a genuine commitment to fairness and transparency.</p>
                        </div>
                    </div>
                </div>

                <!-- People & Terms Tab -->
                <div class="tab-content" id="people">
                    <div class="tab-header">
                        <h3>Featured Experts</h3>
                    </div>
                    <div class="people-section">
                        <div class="person-card-enhanced">
                            <img src="https://i.pravatar.cc/120?img=45" alt="Dr. Sarah Chen" class="person-photo">
                            <div class="person-details">
                                <h4>Dr. Sarah Chen</h4>
                                <span class="person-title">AI Ethics Researcher, Stanford University</span>
                                <p class="person-description">Dr. Chen is a leading voice in AI ethics research, specializing in algorithmic bias and fairness. She holds a Ph.D. in Computer Science from MIT and has published over 50 peer-reviewed papers. Her work has influenced policy discussions at the UN and EU, and she serves on the advisory board of several major tech companies.</p>
                                <div class="person-links">
                                    <a href="#" class="person-link">Stanford Profile</a>
                                    <a href="#" class="person-link">Google Scholar</a>
                                    <a href="#" class="person-link">Twitter</a>
                                </div>
                            </div>
                        </div>

                        <div class="person-card-enhanced">
                            <img src="https://i.pravatar.cc/120?img=33" alt="Professor Michael Rodriguez" class="person-photo">
                            <div class="person-details">
                                <h4>Professor Michael Rodriguez</h4>
                                <span class="person-title">Professor of Computer Science, UC Berkeley</span>
                                <p class="person-description">Professor Rodriguez is the author of "Fair Algorithms: A Guide to Ethical Machine Learning" and teaches one of Berkeley's most popular courses on algorithmic fairness. His research focuses on developing frameworks for transparent and accountable AI systems, with applications in criminal justice reform and financial inclusion.</p>
                                <div class="person-links">
                                    <a href="#" class="person-link">UC Berkeley Profile</a>
                                    <a href="#" class="person-link">Publications</a>
                                    <a href="#" class="person-link">LinkedIn</a>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="tab-header" style="margin-top: 40px;">
                        <h3>Key Terms & Concepts</h3>
                    </div>
                    <div class="terms-section">
                        <div class="term-card">
                            <div class="term-header">
                                <h4>Algorithmic Bias</h4>
                                <span class="term-tag">Mentioned at 05:23</span>
                            </div>
                            <p>Systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one group over another. Bias can emerge from biased training data, flawed algorithm design, or unintended use of the technology.</p>
                        </div>

                        <div class="term-card">
                            <div class="term-header">
                                <h4>Black Box Problem</h4>
                                <span class="term-tag">Mentioned at 12:47</span>
                            </div>
                            <p>The difficulty in understanding and explaining how complex AI systems, particularly deep learning models, arrive at their decisions. The opacity of these systems makes it challenging to audit their behavior or identify potential biases.</p>
                        </div>

                        <div class="term-card">
                            <div class="term-header">
                                <h4>Explainable AI (XAI)</h4>
                                <span class="term-tag">Mentioned at 15:30</span>
                            </div>
                            <p>A set of processes and methods that enable human users to understand and trust AI model outputs. XAI techniques help describe a model's behavior, assess its expected impact, and identify potential biases or errors.</p>
                        </div>

                        <div class="term-card">
                            <div class="term-header">
                                <h4>SHAP Values</h4>
                                <span class="term-tag">Mentioned at 15:30</span>
                            </div>
                            <p>SHapley Additive exPlanations‚Äîa method based on game theory that calculates the contribution of each feature to a model's prediction. SHAP values provide consistent and locally accurate explanations of AI decisions.</p>
                        </div>

                        <div class="term-card">
                            <div class="term-header">
                                <h4>EU AI Act</h4>
                                <span class="term-tag">Mentioned at 18:32</span>
                            </div>
                            <p>The European Union's comprehensive legislation to regulate artificial intelligence. It categorizes AI systems by risk level (minimal, limited, high, and unacceptable) and imposes requirements accordingly, with stricter rules for high-risk applications.</p>
                        </div>
                    </div>
                </div>

                <!-- Translations Tab -->
                <div class="tab-content" id="translations">
                    <div class="tab-header">
                        <h3>Article Translations</h3>
                    </div>
                    <div class="translations-section">
                        <div class="translation-selector">
                            <label>Translate article to:</label>
                            <select class="control-select">
                                <option value="">Select language...</option>
                                <option value="es">Spanish (Espa√±ol)</option>
                                <option value="fr">French (Fran√ßais)</option>
                                <option value="de">German (Deutsch)</option>
                                <option value="ja">Japanese (Êó•Êú¨Ë™û)</option>
                                <option value="zh">Chinese (‰∏≠Êñá)</option>
                                <option value="ru">Russian (–†—É—Å—Å–∫–∏–π)</option>
                                <option value="pt">Portuguese (Portugu√™s)</option>
                                <option value="ar">Arabic (ÿßŸÑÿπÿ±ÿ®Ÿäÿ©)</option>
                            </select>
                        </div>
                        <div class="translation-info">
                            <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                                <circle cx="12" cy="12" r="10"/>
                                <line x1="2" y1="12" x2="22" y2="12"/>
                                <path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/>
                            </svg>
                            <h4>Neural Machine Translation</h4>
                            <p>This article can be translated into multiple languages using state-of-the-art neural machine translation models. Translations are professionally reviewed for accuracy and cultural appropriateness.</p>
                            <div class="translation-features">
                                <div class="feature">‚úì Context-aware translation</div>
                                <div class="feature">‚úì Technical term preservation</div>
                                <div class="feature">‚úì 95%+ accuracy rate</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Metadata Tab -->
                <div class="tab-content" id="metadata">
                    <div class="tab-header">
                        <h3>Video Information</h3>
                    </div>
                    
                    <div class="metadata-section">
                        <h4>Categories & Tags</h4>
                        <div class="tag-cloud">
                            <span class="tag">Artificial Intelligence</span>
                            <span class="tag">Machine Learning</span>
                            <span class="tag">Ethics</span>
                            <span class="tag">Technology</span>
                            <span class="tag">Algorithmic Bias</span>
                            <span class="tag">Data Science</span>
                            <span class="tag">Research</span>
                            <span class="tag">Policy</span>
                            <span class="tag">Regulation</span>
                        </div>
                    </div>

                    <div class="metadata-section">
                        <h4>Related Videos</h4>
                        <div class="related-items">
                            <a href="#" class="related-item">
                                <img src="https://picsum.photos/160/90?random=12" alt="Related video">
                                <div class="related-content">
                                    <h5>Understanding Neural Networks</h5>
                                    <span class="related-meta">Tech Insights ‚Ä¢ 18:24</span>
                                </div>
                            </a>
                            <a href="#" class="related-item">
                                <img src="https://picsum.photos/160/90?random=13" alt="Related video">
                                <div class="related-content">
                                    <h5>Data Privacy in the AI Age</h5>
                                    <span class="related-meta">Tech Insights ‚Ä¢ 22:15</span>
                                </div>
                            </a>
                            <a href="#" class="related-item">
                                <img src="https://picsum.photos/160/90?random=14" alt="Related video">
                                <div class="related-content">
                                    <h5>The Future of Work and Automation</h5>
                                    <span class="related-meta">Tech Insights ‚Ä¢ 26:40</span>
                                </div>
                            </a>
                        </div>
                    </div>

                    <div class="metadata-section">
                        <h4>Resources & Links</h4>
                        <ul class="resource-list">
                            <li><a href="#">Stanford Center for AI Ethics</a></li>
                            <li><a href="#">EU AI Act Official Documentation</a></li>
                            <li><a href="#">Algorithmic Fairness Research Papers</a></li>
                            <li><a href="#">SHAP Documentation and Tutorials</a></li>
                            <li><a href="#">Partnership on AI Resources</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </aside>

        <!-- Action Bar -->
        <div class="action-bar">
            <div class="action-group">
                <button class="action-btn">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"/>
                        <polyline points="16 6 12 2 8 6"/>
                        <line x1="12" y1="2" x2="12" y2="15"/>
                    </svg>
                    Share
                </button>
                <button class="action-btn">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M19 21l-7-5-7 5V5a2 2 0 0 1 2-2h10a2 2 0 0 1 2 2z"/>
                    </svg>
                    Save
                </button>
                <button class="action-btn">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <polyline points="6 9 6 2 18 2 18 9"/>
                        <path d="M6 18H4a2 2 0 0 1-2-2v-5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2v5a2 2 0 0 1-2 2h-2"/>
                        <rect x="6" y="14" width="12" height="8"/>
                    </svg>
                    Print
                </button>
                <button class="action-btn">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                        <polyline points="7 10 12 15 17 10"/>
                        <line x1="12" y1="15" x2="12" y2="3"/>
                    </svg>
                    Export PDF
                </button>
            </div>
        </div>
    </div>

    <footer class="site-footer">
        <div class="footer-content">
            <div class="footer-section">
                <h4>VideoArticle</h4>
                <p>Transform video content into engaging, in-depth articles with transcriptions, translations, and expert insights.</p>
            </div>
            <div class="footer-section">
                <h4>Explore</h4>
                <a href="#">Technology</a>
                <a href="#">Science</a>
                <a href="#">Education</a>
                <a href="#">Business</a>
            </div>
            <div class="footer-section">
                <h4>Resources</h4>
                <a href="#">About</a>
                <a href="#">Blog</a>
                <a href="#">API</a>
                <a href="#">Contact</a>
            </div>
        </div>
        <div class="footer-bottom">
            <p>&copy; 2024 VideoArticle. All rights reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
